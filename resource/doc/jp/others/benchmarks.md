# ベンチマークテスト

### ベンチマーク結果に影響を与える要因は何ですか？
- クライアントからサーバーへのネットワーク遅延（内部ネットワークまたはローカルでの推奨）
- クライアントからサーバーへの帯域幅（内部ネットワークまたはローカルでの推奨）
- HTTP keep-aliveの有無（有効化をお勧め）
- 十分な並行数（外部ベンチマークではできるだけ大きな並行数を推奨）
- サーバープロセスの適切な数（helloworldの場合、CPU数と同じ数のプロセスを推奨。データベースサービスの場合、CPU数の4倍以上を推奨）
- ビジネス自体のパフォーマンス（外部データベースを使用しているかなど）

### HTTP keep-aliveとは何ですか？
HTTP Keep-Aliveメカニズムは、単一のTCP接続を使用して複数のHTTPリクエストとレスポンスを送信する技術であり、性能テスト結果に大きな影響を与えます。 keep-aliveを無効にすると、QPSが大幅に低下する可能性があります。

現在、ほとんどのブラウザはデフォルトでkeep-aliveを有効にしており、つまり、ブラウザが特定のHTTPアドレスにアクセスした後、接続を一時的に保持しておき、次回のリクエスト時にこの接続を再利用してパフォーマンスを向上させます。
ベンチマークテストを実施する際は、keep-aliveを有効にすることをお勧めします。

### ベンチマークテスト時にHTTP keep-aliveを有効にするにはどうすればよいですか？
abプログラムを使用している場合は、-kオプションを追加する必要があります。 例：`ab -n100000 -c200 -k http://127.0.0.1:8787/`
apipostの場合、gzipヘッダーを応答ヘッダーに返さないとkeep-aliveを有効にすることができません（apipostのバグ、以下を参照）。
その他のベンチマークプログラムでは一般的にデフォルトでkeep-aliveが有効になっています。

### 外部ネットワークでのベンチマークテスト時になぜQPSが低いのですか？
外部ネットワークの遅延が大きいため、QPSが低いのは正常な現象です。 たとえば、バイドゥページのベンチマークテストではQPSが数十しかありません。
内部ネットワークまたはローカルでのベンチマークをお勧めし、ネットワーク遅延の影響を排除します。
外部ネットワークでベンチマークを実行する必要がある場合は、帯域幅を十分に確保するために並行数を増やすことでスループットを向上させることができます。

### なぜnginxプロキシを経由すると性能が低下するのですか？
Nginxの実行にはシステムリソースが必要とされます。同時に、Nginxとwebmanの間の通信も一定のリソースを消費します。
ただし、システムリソースは限られており、Webmanはすべてのシステムリソースを取得できないため、システム全体のパフォーマンスが若干低下することは正常です。
Nginxプロキシによる性能の影響をできるだけ減らすためには、Nginxログを無効にし（`access_log off;`）、Nginxからwebmanへのkeep-aliveを有効にすることを検討してください。

また、httpsはhttpよりもリソースを消費します。httpsはSSL/TLSハンドシェイク、データの暗号化・復号化、パケットサイズの増加などが必要とされ、これらがパフォーマンスの低下につながります。
httpsを使用する場合、HTTP keep-aliveを有効にすることをお勧めします。

### システムが性能の限界に達したことをどのように知ればよいですか？
一般的に、CPUが100%に達すると、システムの性能が限界に達したことを示します。 CPUに余裕がある場合はまだ限界に達していないということであり、この場合、並行数を適切に増やすことでQPSを向上させることができます。
しかし、並行数を増やしてもQPSが向上しない場合、webmanプロセスの数が不足している可能性があります。 この場合は、適切にwebmanプロセスを増やす必要があります。 それでもQPSが向上しない場合は、帯域幅が十分かどうかを検討してください。

### なぜ私のベンチマーク結果でwebmanのパフォーマンスがgoのginフレームワークよりも低いのですか？
[techempower](https://www.techempower.com/benchmarks/#section=data-r21&hw=ph&test=db&l=zijnjz-6bj&a=2&f=1ekg-cbcw-2t4w-27wr68-pc0-iv9slc-0-1ekgw-39g-kxs00-o0zk-5jsetl-2x8doc-2)によるベンチマーク結果では、Webmanは純粋なテキスト、データベースクエリ、データベースアップデートなどのすべての指標でginよりも約1倍高いことが示されています。
もしあなたの結果が異なる場合、それはwebmanでORMを使用していることによる大きなパフォーマンスの低下が原因かもしれません。webman+ネイティブPDOとgin+ネイティブSQLを比較してみてください。

###	webmanでORMを使用すると、パフォーマンスはどの程度低下しますか？
以下は一連のベンチマークデータです

**環境**
アリババクラウド4コア4G、10万件のレコードからランダムに1件のデータをJSONで取得します。

**ネイティブPDOを使用する場合**
webmanのQPSは1.78万です

**LaravelのDb::table()を使用する場合**
webmanのQPSが0.94万QPSに低下

**LaravelのModelを使用する場合**
webmanのQPSが0.72万QPSに低下

ThinkORMの結果も同様で、あまり違いはありません。

> **注意**
> ORMを使用するとパフォーマンスが低下しますが、ほとんどのビジネスにとって十分です。開発効率、メンテナンス性、パフォーマンスなど、複数の観点でバランスを取るべきです。

### なぜapipostを使用したベンチマークのQPSが低いのですか？
apipostのベンチマークテストモジュールにバグがあり、サーバーがgzipヘッダーを返さない場合はkeep-aliveを維持できず、パフォーマンスが大幅に低下します。
解決策として、データを圧縮してgzipヘッダーを追加して応答することがあります。例：
```php
<?php
namespace app\controller;
class IndexController
{
    public function index()
    {
        return response(gzencode('hello webman'))->withHeader('Content-Encoding', 'gzip');
    }
}
```
また、apipostは一部のケースでは満足のいくストレスをかけることができず、同じ並行数でapipostを使用すると、QPSがabよりも約50％低くなることがあります。
ベンチマークテストでは、apipostの代わりにab、wrk、または他の専門のベンチマークソフトウェアを使用することをお勧めします。

### 適切なプロセス数の設定
webmanはデフォルトでcpu * 4のプロセス数を起動します。実際には、ネットワークIOのないhelloworldビジネスのベンチマークテストでは、プロセス数をCPUコア数と同じに設定することが最適であり、これによりプロセスの切り替えオーバーヘッドを減らすことができます。
データベース、RedisなどのブロッキングIOビジネスの場合、プロセス数はCPUの3〜8倍に設定できます。なぜなら、こうした場合はより多くのプロセスが必要なため、並行性を高めることができるからです。ブロッキングIO時のプロセス切り替えのオーバーヘッドはほぼ無視できるためです。

### ベンチマークの参考範囲

**クラウドサーバー 4コア 4G 16プロセス ローカル/内部ベンチマーク**

| - | keep-aliveを有効 | keep-aliveを無効 |
|--|-----|-----|
| helloworld | 8-16万QPS | 1-3万QPS |
| データベースクエリ | 1-2万QPS | 1万QPS |

[**サードパーティーtechempowerのベンチマークデータ**](https://www.techempower.com/benchmarks/#section=data-r21&l=zik073-6bj&test=db)


### ベンチマークのコマンド例

**ab**
```
# 100,000リクエスト 200並行 keep-aliveを有効
ab -n100000 -c200 -k http://127.0.0.1:8787/

# 100,000リクエスト 200並行 keep-aliveを無効
ab -n100000 -c200 http://127.0.0.1:8787/
```

**wrk**
```
# 200並行 10秒間ベンチマークテスト keep-aliveを有効（デフォルト）
wrk -c 200 -d 10s http://example.com
```
